{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa73290",
   "metadata": {},
   "source": [
    "## 문제 6\n",
    "\n",
    "**Kaggle 형** train_prob.csv로 문제 target을 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 target 예측하여 다음과 같은 형식의 answer6.csv를 만들어라.\n",
    "\n",
    "id, target\n",
    "\n",
    "0, 6.9\n",
    "\n",
    "5, 7.8\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "**평가지표**\n",
    "\n",
    "$RMSE(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y_i-\\hat{y_i})^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8453bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78d0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 불러 옵니다.\n",
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "# targetA를 예측하는 모델을 활용하기 위해 가져옵니다.\n",
    "df_train['targetA'] = df_train['target'] <= 7.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d28634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터를 불러 옵니다.\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57696ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리를 가져왔습니다.\n",
    "repl_list= [\n",
    "    ('cat3', {'B': 'C'}, [83634, 147361, 9005]),\n",
    "    ('cat4', {'A': 'B', 'D': 'B'}, [239397, 603]),\n",
    "    ('cat6', {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'}, [234203, 5145, 652]),\n",
    "    ('cat7', {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'}, [4606, 19784, 214027, 1583]),\n",
    "    ('cat8', {'B': 'G', 'F': 'E'}, [30338, 96743, 2953, 76085, 33881]),\n",
    "    ('cat9', {'C': 'H', 'D': 'B', 'E': 'L'}, [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968]),\n",
    "]\n",
    "\n",
    "for c, d, cnt in repl_list:\n",
    "    df_train[c] = df_train[c].replace(d)\n",
    "    #df_test[c] = df_test[c].replace(d) 일부러 아래 고찰을 위해 주석처리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7bc8b",
   "metadata": {},
   "source": [
    "## OneHotEncoder 시  Unknown 범주값 대처법에 대한 고찰\n",
    "\n",
    "Unknown 범주값: Test 셋에서 Train에 나오지 않는 범주값을 일컫습니다.\n",
    "\n",
    "Unknown 범주값에 대해서 OneHotEncoder 에서 handle_unknown='ignore'로 하면,\n",
    "\n",
    "그 변수에 대해서는 모든 값이 0이 가변수를 반환합니다.\n",
    "\n",
    "하지만, OneHotEncoder를 handle_unknown='ignore'로 하면 drop='first'를 사용할 수 없습니다.\n",
    "\n",
    "(1.0 이후 버젼은 허용합니다. 쩝...)\n",
    "\n",
    "선형 모델을 사용하지 않으면 문제 없습니다. \n",
    "\n",
    "그런데, 선형 모델을 사용한다면 drop='first'를 사용하지 않으면, 가변수 간에 완전한 다중공선성을 갖게 됩니다.\n",
    "\n",
    "이렇게 되면, 선형 모델의 계수(coefficient)가 큰 값을 지니게 됩니다. \n",
    "\n",
    "따라서, 불안정한 모델이 만들어지게 되고, \n",
    "\n",
    "학습에서 등장하지 않은 경우(Ex 가변수가 모두 0)에 대해서는 전혀 엉뚱한 값이 나오게 됩니다.\n",
    "\n",
    "선형 모델을 사용하고자 하고, 사용하고자 하는 변수가 그렇다면.\n",
    "\n",
    "이에 대한 대처법 test에 train에 나오지 않는 범주값이 나올 경우 대체 시켜줍니다. \n",
    "\n",
    "   Ex) 가장 많이 나온 범주\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3855444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat0                 {}\n",
       "cat1                 {}\n",
       "cat2                 {}\n",
       "cat3                {B}\n",
       "cat4             {A, D}\n",
       "cat5                 {}\n",
       "cat6    {E, H, G, D, I}\n",
       "cat7          {F, A, C}\n",
       "cat8             {F, B}\n",
       "cat9          {E, D, C}\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test에 등장하지 않은 내용이 있는지 검사하는 로직입니다. ㅠ.ㅜ \n",
    "# 선형 모델을 사용하겠다면, 출력된 값들은 어찌 됐는 처리가 되야겠죠...\n",
    "df_test.select_dtypes('object').apply(\n",
    "    lambda x: set(x.unique()) - set(df_train[x.name].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a197a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat0    {}\n",
       "cat1    {}\n",
       "cat2    {}\n",
       "cat3    {}\n",
       "cat4    {}\n",
       "cat5    {}\n",
       "cat6    {}\n",
       "cat7    {}\n",
       "cat8    {}\n",
       "cat9    {}\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요런 식으로 말이죠. 이렇게 해야지 handle_unknown='ignore'를 쓰지 않을 수 있게 되어, drop='first'를 사용할 수 있습니다.\n",
    "for c, d, cnt in repl_list:\n",
    "    df_test[c] = df_test[c].replace(d)\n",
    "df_test.select_dtypes('object').apply(\n",
    "    lambda x: set(x.unique()) - set(df_train[x.name].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabd02c",
   "metadata": {},
   "source": [
    "## OneHotEncoder시 Unknown 범주값 대처법에 대한 고찰에 대한 마무리 \n",
    "\n",
    "**선형 모델(LinearRegression, LogisticRegression, ...)**을 사용을 한다면 test에 train에 등장하지 않은 것들이 없게 처리를 해주고,\n",
    "\n",
    "OneHotEncoder를 사용시 drop='first'를 사용하시어 안정적인 모델을 만드는 것을 권유 드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503d1c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "      <th>targetA</th>\n",
       "      <th>prob_A</th>\n",
       "      <th>prob_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29503</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30163</td>\n",
       "      <td>0.32551</td>\n",
       "      <td>0.26982</td>\n",
       "      <td>0.19329</td>\n",
       "      <td>0.39034</td>\n",
       "      <td>0.30002</td>\n",
       "      <td>6.66255</td>\n",
       "      <td>True</td>\n",
       "      <td>0.568599</td>\n",
       "      <td>2.792056e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113326</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65004</td>\n",
       "      <td>0.63958</td>\n",
       "      <td>0.60535</td>\n",
       "      <td>0.70951</td>\n",
       "      <td>0.71664</td>\n",
       "      <td>0.78782</td>\n",
       "      <td>5.98141</td>\n",
       "      <td>True</td>\n",
       "      <td>0.899473</td>\n",
       "      <td>2.414650e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199507</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22571</td>\n",
       "      <td>0.48717</td>\n",
       "      <td>0.33999</td>\n",
       "      <td>0.51461</td>\n",
       "      <td>0.37367</td>\n",
       "      <td>0.69462</td>\n",
       "      <td>6.60870</td>\n",
       "      <td>True</td>\n",
       "      <td>0.602656</td>\n",
       "      <td>2.030176e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346281</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45999</td>\n",
       "      <td>0.79100</td>\n",
       "      <td>0.62269</td>\n",
       "      <td>0.83624</td>\n",
       "      <td>0.78785</td>\n",
       "      <td>0.30893</td>\n",
       "      <td>5.42339</td>\n",
       "      <td>True</td>\n",
       "      <td>0.985535</td>\n",
       "      <td>1.506759e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137333</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49416</td>\n",
       "      <td>0.89742</td>\n",
       "      <td>0.59422</td>\n",
       "      <td>0.72298</td>\n",
       "      <td>0.72535</td>\n",
       "      <td>0.82115</td>\n",
       "      <td>8.34177</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>6.609742e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...    cont8  \\\n",
       "id                                                        ...            \n",
       "29503     A    B    A    C    B    B    A    E    E    F  ...  0.30163   \n",
       "113326    A    B    A    A    B    D    A    E    C    H  ...  0.65004   \n",
       "199507    A    B    B    A    B    B    A    E    A    L  ...  0.22571   \n",
       "346281    A    A    A    D    B    D    A    E    C    F  ...  0.45999   \n",
       "137333    A    A    A    C    B    D    A    D    C    K  ...  0.49416   \n",
       "\n",
       "          cont9   cont10   cont11   cont12   cont13   target  targetA  \\\n",
       "id                                                                      \n",
       "29503   0.32551  0.26982  0.19329  0.39034  0.30002  6.66255     True   \n",
       "113326  0.63958  0.60535  0.70951  0.71664  0.78782  5.98141     True   \n",
       "199507  0.48717  0.33999  0.51461  0.37367  0.69462  6.60870     True   \n",
       "346281  0.79100  0.62269  0.83624  0.78785  0.30893  5.42339     True   \n",
       "137333  0.89742  0.59422  0.72298  0.72535  0.82115  8.34177    False   \n",
       "\n",
       "          prob_A        prob_B  \n",
       "id                              \n",
       "29503   0.568599  2.792056e-03  \n",
       "113326  0.899473  2.414650e-05  \n",
       "199507  0.602656  2.030176e-03  \n",
       "346281  0.985535  1.506759e-07  \n",
       "137333  0.005337  6.609742e-01  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제3의 내용을 응용합니다.\n",
    "from scipy.stats import norm\n",
    "mu_A, std_A = 6.769, 0.616\n",
    "mu_B, std_B = 8.123, 0.527\n",
    "df_train_A = df_train.assign(\n",
    "    prob_A = 1 - norm.cdf(df_train['target'], loc=mu_A, scale=std_A), # A의 분포에서, 우측 꼬리에 해당하는 영역을 구합니다.\n",
    "    prob_B = norm.cdf(df_train['target'], loc=mu_B, scale=std_B) # B의 분포에서, 좌측 꼬리에 해당하는 영역을 구합니다.\n",
    ")\n",
    "df_train_A = df_train_A.query('prob_B < 0.01 or prob_A < 0.01').copy()\n",
    "df_train_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc86c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a288606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=False),\n",
       "                                                  ['cat0', 'cat1', 'cat2',\n",
       "                                                   'cat3', 'cat4', 'cat...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=0.25,\n",
       "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "                               max_depth=2, min_child_weight=1, missing=None,\n",
       "                               n_estimators=500, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=123,\n",
       "                               reg_alpha=0.1, reg_lambda=0.1,\n",
       "                               scale_pos_weight=1, seed=None, silent=True,\n",
       "                               subsample=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "X_cont = ['cont{}'.format(i) for i in range(14)]\n",
    "X_cat = ['cat{}'.format(i) for i in range(10)]\n",
    "X_xgb = X_cont + X_cat\n",
    "ct_xgb = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), X_cat),\n",
    "    ('pt', 'passthrough', X_cont)\n",
    "])\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "    max_depth=2, #트리의 최대 깊이: 2\n",
    "    reg_alpha=0.1, # L1 규제: 0.1\n",
    "    reg_lambda=0.1, # L2 규제: 0.1\n",
    "    colsample_bytree=0.25, #트리 당 컬럼 샘플링 비율: 0.25\n",
    "    n_estimators=500, #트리의 수: 500\n",
    "    random_state=123\n",
    ")\n",
    "clf_xgb = make_pipeline(ct_xgb, clf_xgb)\n",
    "clf_xgb.fit(df_train_A[X_xgb], df_train_A['targetA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0e44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetA 예측 확률을 파생 변수로 삼습니다.\n",
    "df_train['target_probA'] = clf_xgb.predict_proba(df_train[X_xgb])[:, 1]\n",
    "df_test['target_probA'] = clf_xgb.predict_proba(df_test[X_xgb])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de9325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 4에서 만든 파생변수를 거져 옵니다.\n",
    "q = [i / 100 for i in range(101)] # np.linspace(0, 1, 101)\n",
    "for i in range(0, 14):\n",
    "    col = 'cont{}'.format(i)\n",
    "    col_q = col + '_q'\n",
    "    q_val = df_train[col].quantile(q)\n",
    "    q_val.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "    q_int = pd.cut(df_train[col], q_val)\n",
    "    q_mean = df_train.groupby(q_int)['target'].mean()\n",
    "    df_train[col_q] = q_int.map(q_mean).astype('float')\n",
    "    df_test[col_q] = pd.cut(df_test[col], q_val).map(q_mean).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d704932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "cv = KFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2aa6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.70886461, -0.71123524, -0.71662955, -0.70661583, -0.70125227]),\n",
       " -0.708919501126037)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 만들어봅니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_cont = ['cont{}_q'.format(i) for i in range(14)] + ['target_probA']\n",
    "X_cat = ['cat{}'.format(i) for i in range(10)]\n",
    "X_lr = X_cont + X_cat\n",
    "\n",
    "ct_lr = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(sparse=False, drop='first'), X_cat),\n",
    "    ('pt', 'passthrough', X_cont)\n",
    "])\n",
    "\n",
    "reg_lr = make_pipeline(ct_lr, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr, df_train[X_lr], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d1cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 결과를 만듭니다.\n",
    "reg_lr.fit(df_train[X_lr], df_train['target'])\n",
    "pd.DataFrame(\n",
    "    reg_lr.predict(df_test[X_lr]),\n",
    "    columns=['target'],\n",
    "    index=df_test.index\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f002e764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7188957818884829, 0.8478772209987027)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답셋과 비교합니다.\n",
    "mse = mean_squared_error(df_ans['target'], reg_lr.predict(df_test[X_lr]))\n",
    "mse, mse ** 0.5 # RMSE로 뽑아옵니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4191d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.71064094, -0.7128614 , -0.71806878, -0.7083828 , -0.70272486]),\n",
       " -0.7105357560846794)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost 모델로 해봅니다.\n",
    "# 실행시간의 압박이 있습니다.\n",
    "X_cont = ['cont{}'.format(i) for i in range(14)] + ['target_probA']\n",
    "X_cat = ['cat{}'.format(i) for i in range(10)]\n",
    "X_xgb = X_cont + X_cat\n",
    "ct_xgb = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), X_cat),\n",
    "    ('pt', 'passthrough', X_cont)\n",
    "])\n",
    "\n",
    "reg_xgb = xgb.XGBRegressor(\n",
    "    max_depth=2, \n",
    "    random_state=123,\n",
    "    colsample_bytree=0.25, \n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "reg_xgb = make_pipeline(ct_xgb, reg_xgb)\n",
    "scores_ = cross_val_score(reg_xgb, df_train[X_xgb], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4449162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.717977620100122, 0.8473356006330207)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb.fit(df_train[X_xgb], df_train['target'])\n",
    "# 정답셋과 비교합니다.\n",
    "mse = mean_squared_error(df_ans['target'], reg_xgb.predict(df_test[X_xgb]))\n",
    "mse, mse ** 0.5 # RMSE로 뽑아옵니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44a46694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.70876365, -0.71104412, -0.71636808, -0.70652537, -0.70100968]),\n",
       " -0.7087421803791012)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 모델을 앙상블 해봅니다.\n",
    "# 실행시간의 압박이 있습니다.\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "X_vt = ['cont{}'.format(i) for i in range(14)] + ['cont{}_q'.format(i) for i in range(14)] + X_cat + ['target_probA']\n",
    "reg_vt = VotingRegressor([\n",
    "    ('lr', reg_lr),\n",
    "    ('xgb', reg_xgb)\n",
    "])\n",
    "scores_ = cross_val_score(reg_vt, df_train[X_vt], df_train['target'], cv=cv, scoring='neg_mean_squared_error')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abdbc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 최종 모델로 합니다.\n",
    "# VotingRegressor가 가장 좋네요\n",
    "reg_vt.fit(df_train[X_vt], df_train['target'])\n",
    "pd.DataFrame(\n",
    "    reg_vt.predict(df_test[X_vt]),\n",
    "    columns=['target'],\n",
    "    index=df_test.index\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d538b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.717490926802164, 0.8470483615485978)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답셋과 비교합니다. 아주 미묘하게 좋습니다.\n",
    "mse = mean_squared_error(df_ans['target'], reg_vt.predict(df_test[X_vt]))\n",
    "mse, mse ** 0.5 # RMSE로 뽑아옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f7af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
